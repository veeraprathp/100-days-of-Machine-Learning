{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8iRbk_5SkXv",
        "outputId": "449221c4-d914-4f60-fa0e-153c3cfaedb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer , AutoModelForCausalLM\n"
      ],
      "metadata": {
        "id": "b1A2nKauSn5i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3ZL7S_aOS46R",
        "outputId": "3fa78d11-4eef-4d7b-937b-bcab084329a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gpt2'\n",
        "tokenizer =AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "YHX_J5B7TJAS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =AutoModelForCausalLM.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "hLXjZqhM4LpC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input(\"Please enter some text: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-jLIkvr8Nz4",
        "outputId": "c004bddd-d79a-4b2f-eff8-4cdc95b1d35d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter some text: i am happy to share my 54 day of ml challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input_text\n",
        "\n",
        "max_lenght = 128\n",
        "\n",
        "input_ids = tokenizer(input_text, return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "ld1OPVTG4fet"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6To0mFe65F98",
        "outputId": "5802fe0c-0a31-4704-d1d0-0aa03c30b99d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   72,   716,  3772,   284,  2648,   616,  7175,  1110,   286, 25962,\n",
              "          4427]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = input_ids['input_ids'].to(device)"
      ],
      "metadata": {
        "id": "Xeib2t815KRf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length =128"
      ],
      "metadata": {
        "id": "bALlybsG7Blt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False,repetition_penalty=2.0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8V910Bh6wjs",
        "outputId": "c74904ae-d525-4e1f-e5ee-769ebbf464d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RBZ56A6-60",
        "outputId": "2678df11-0fee-4cde-dc0f-48e00e75733f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   72,   716,  3772,   284,  2648,   616,  7175,  1110,   286, 25962,\n",
              "          4427,   351,   345,   477,    13,   198,   198,    40,  1053,   587,\n",
              "          1762,   319,   428,  1628,   329,   257,   981,   783,    11,   290,\n",
              "           314,  1101,  1107,  6568,   546,   340,    13,   632,   338,  1016,\n",
              "           284,   307,   257,  1256,   286,  1257,    11,   290,   314,  2911,\n",
              "           345,  3730,  2883,   340,   355,   881,   355,   314,   466,     0,\n",
              "           198,   198,  1532,   345,   423,   597,  2683,   393,  3651,    11,\n",
              "          1254,  1479,   284,  2666,   606,   287,   262,  3651,  2174,     0,\n",
              "           198,   198, 14592, 50256]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vwZN4657KW8",
        "outputId": "fd7fc23d-f98e-4480-bcfc-099356465304"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am happy to share my 54 day of ml challenge with you all.\n",
            "\n",
            "I've been working on this project for a while now, and I'm really excited about it. It's going to be a lot of fun, and I hope you guys enjoy it as much as I do!\n",
            "\n",
            "If you have any questions or comments, feel free to leave them in the comments below!\n",
            "\n",
            "Advertisements<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_nucleus = model.generate(input_ids, max_length=max_length, do_sample=True, top_p=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOB3ciFj7Sx9",
        "outputId": "ee300b64-03ad-4a10-f4b4-dcadfdfea71f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4SQY5oYl7lzI",
        "outputId": "970d9779-803c-4fdd-c562-73db74f9df1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i am happy to share my 54 day of ml challenge with you all.\\n\\nI've been working on this project for a while now, and I'm really excited about it. It's going to be a lot of fun, and I hope you guys enjoy it as much as I do!\\n\\nIf you have any questions or comments, feel free to leave them in the comments below!\\n\\nAdvertisements<|endoftext|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HR1J66cL-YGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}